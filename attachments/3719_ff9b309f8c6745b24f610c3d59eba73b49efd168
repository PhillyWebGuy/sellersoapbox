{\rtf1\ansi\ansicpg1252\deff0\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\sa200\sl276\slmult1\lang9\f0\fs22\par
\par
\par
    Author: Adam Rogers. Adam Rogers\tab Science Date of Publication: 08.06.15.\par
\par
Imagine an election\emdash a close one. You\rquote re undecided. So you type the name of one of the candidates into your search engine of choice. (Actually, let\rquote s not be coy here. In most of the world, one search engine dominates; in Europe and North America, it\rquote s Google.) And Google coughs up, in fractions of a second, articles and facts about that candidate. Great! Now you are an informed voter, right? But a study published this week says that the order of those results, the ranking of positive or negative stories on the screen, can have an enormous influence on the way you vote. And if the election is close enough, the effect could be profound enough to change the outcome.\par
\par
In other words: Google\rquote s ranking algorithm for search results could accidentally steal the presidency. \ldblquote We estimate, based on win margins in national elections around the world,\rdblquote  says Robert Epstein, a psychologist at the American Institute for Behavioral Research and Technology and one of the study\rquote s authors, \ldblquote that Google could determine the outcome of upwards of 25 percent of all national elections.\rdblquote\par
\par
Epstein\rquote s paper combines a few years\rquote  worth of experiments in which Epstein and his colleague Ronald Robertson gave people access to information about the race for prime minister in Australia in 2010, two years prior, and then let the mock-voters learn about the candidates via a simulated search engine that displayed real articles.\par
\par
One group saw positive articles about one candidate first; the other saw positive articles about the other candidate. (A control group saw a random assortment.) The result: Whichever side people saw the positive results for, they were more likely to vote for\emdash by more than 48 percent. The team calls that number the \ldblquote vote manipulation power,\rdblquote  or VMP. The effect held\emdash strengthened, even\emdash when the researchers swapped in a single negative story into the number-four and number-three spots. Apparently it made the results seem even more neutral and therefore more trustworthy.\par
\par
But of course that was all artificial\emdash in the lab. So the researchers packed up and went to India in advance of the 2014 Lok Sabha elections, a national campaign with 800 million eligible voters. (Eventually 430 million people voted over the weeks of the actual election.) \ldblquote I thought this time we\rquote d be lucky if we got 2 or 3 percent, and my gut said we\rquote re gonna get nothing,\rdblquote  Epstein says, \ldblquote because this is an intense, intense election environment.\rdblquote  Voters get exposed, heavily, to lots of other information besides a mock search engine result.\par
\par
The team 2,150 found undecided voters and performed a version of the same experiment. And again, VMP was off the charts. Even taking into account some sloppiness in the data-gathering and a tougher time assessing articles for their positive or negative valence, they got an overall VMP of 24 percent. \ldblquote In some demographic groups in India we had as high as about 72 percent.\rdblquote\par
\par
The effect doesn\rquote t have to be enormous to have an enormous effect.\par
\par
The fact that media, including whatever search and social deliver, can affect decision-making isn\rquote t exactly news. The \ldblquote Fox News Effect\rdblquote  says that towns that got the conservative-leaning cable channel tended to become more conservative in their voting in the 2000 election. A well-known effect called recency means that people make decisions based on the last thing they heard. Placement on a list also has a known effect. And all that stuff might be too transient to make it all the way to a voting booth, or get swamped by exposure to other media. So in real life VMP is probably much less pronounced.\par
\par
But the effect doesn\rquote t have to be enormous to have an enormous effect. The Australian election that Epstein and Robertson used in their experiments came down to a margin of less than 1 percent. Half the presidential elections in US history came down to a margin of less than 8 percent. And presidential elections are really 50 separate state-by-state knife fights, with the focus of campaigns not on poll-tested winners or losers but purple \ldblquote swing states\rdblquote  with razor-thin margins.\par
\par
So even at an order of magnitude smaller than the experimental effect, VMP could have serious consequences. \ldblquote Four to 8 percent would get any campaign manager excited,\rdblquote  says Brian Keegan, a computational social scientist at Harvard Business School. \ldblquote At the end of the day, the fact is that in a lot of races it only takes a swing of 3 or 4 percent. If the search engine is one or two percent, that\rquote s still really persuasive.\rdblquote\par
The Rise of the Machines\par
\par
It\rquote d be easy to go all 1970s-political-thriller on this research, to assume that presidential campaigns, with their ever-increasing level of technological sophistication, might be able to search-engine-optimize their way to victory. But that\rquote s probably not true. \ldblquote It would cost a lot of money,\rdblquote  says David Shor, a data scientist at Civis Analytics, a Chicago-based consultancy that grew out of the first Obama campaign\rquote s technology group. \ldblquote Trying to get the media to present something that is favorable to you is a more favorable strategy.\rdblquote\par
\par
That\rquote s called, in the parlance of political hackery, \ldblquote free media,\rdblquote  and, yes, voters like it. \ldblquote I think that generally people don\rquote t trust campaigns because they tend to have a low opinion of politicians,\rdblquote  Shor says. \ldblquote They are more receptive to information from institutions for which they have more respect.\rdblquote  Plus, in the presidential campaign high season, whoever the Republican and Democratic nominees are will already have high page ranks because they\rquote ll have a huge number of inbound links, one of Google\rquote s key metrics.\par
\par
Search and social media companies can certainly have a new kind of influence, though. During the 2010 US congressional elections, researchers at Facebook exposed 61 million users to a message exhorting them to vote\emdash it didn\rquote t matter for whom\emdash and found they were able to generate 340,000 extra votes across the board.\par
\par
But what if\emdash as Harvard Law professor Jonathan Zittrain has proposed\emdash Facebook didn\rquote t push the \ldblquote vote\rdblquote  message to a random 61 million users? Instead, using the extensive information the social network maintains on all its subscribers, it could hypothetically push specific messaging to supporters or foes of specific legislation or candidates. Facebook could flip an election; Zittrain calls this \ldblquote digital gerrymandering.\rdblquote  And if you think that companies like the social media giants would never do such a thing, consider the way that Google mobilized its users against the Secure Online Privacy Act and PROTECT IP Act, or \ldblquote SOPA-PIPA.\rdblquote\par
\par
In their paper, Epstein and Robertson equate digital gerrymandering to what a political operative might call GOTV\emdash Get Out the Vote, the mobilization of activated supporters. It\rquote s a standard campaign move when your base agrees with your positions but isn\rquote t highly motivated\emdash because they feel disenfranchised, let\rquote s say, or have problems getting to polling places. What they call the \ldblquote search engine manipulation effect,\rdblquote  though, works on undecided voters, swing voters. It\rquote s a method of persuasion.\par
\par
If executives at Google had decided to study the things we\rquote re studying, they could easily have been flipping elections to their liking with no one having any idea. Robert Epstein\par
\par
Again, though, it doesn\rquote t require a conspiracy. It\rquote s possible that, as Epstein says, \ldblquote if executives at Google had decided to study the things we\rquote re studying, they could easily have been flipping elections to their liking with no one having any idea.\rdblquote  But simultaneously more likely and more science-fiction-y is the possibility that this\emdash oh, let\rquote s call it \ldblquote googlemandering,\rdblquote  why don\rquote t we?\emdash is happening without any human intervention at all. \ldblquote These numbers are so large that Google executives are irrelevant to the issue,\rdblquote  Epstein says. \ldblquote If Google\rquote s search algorithm, just through what they call \lquote organic processes,\rquote  ends up favoring one candidate over another, that\rquote s enough. In a country like India, that could send millions of votes to one candidate.\rdblquote\par
\par
As you\rquote d expect, Google doesn\rquote t think it\rquote s likely their algorithm is stealing elections. \ldblquote Providing relevant answers has been the cornerstone of Google\rquote s approach to search from the very beginning. It would undermine people\rquote s trust in our results and company if we were to change course,\rdblquote  says a Google spokesperson, who would only comment on condition of anonymity. In short, the algorithms Google uses to rank search results are complicated, ever-changing, and bigger than any one person. A regulatory action that, let\rquote s say, forced Google to change the first search result in a list on a given candidate would break the very thing that makes Google great: giving right answers very quickly all the time. (Plus, it might violate the First Amendment.)\par
\par
The thing is, though, even though it\rquote s tempting to think of algorithms as the very definition of objective, they\rquote re not. \ldblquote It\rquote s not really possible to have a completely neutral algorithm,\rdblquote  says Jonathan Bright, a research fellow at the Oxford Internet Institute who studies elections. \ldblquote I don\rquote t think there\rquote s anyone in Google or Facebook or anywhere else who\rquote s trying to tweak an election. But it\rquote s something these organizations have always struggled with.\rdblquote  Algorithms reflect the values and worldview of the programmers. That\rquote s what an algorithm is, fundamentally. \ldblquote Do they want to make a good effort to make sure they influence evenly across Democrats and Republicans? Or do they just let the algorithm take its course?\rdblquote  Bright asks.\par
\par
That course might be scary, if Epstein is right. Add the possibility of search rank influence to the individualization Google can already do based on your gmail, google docs, and every other way you\rquote ve let the company hook into you\'85combine that with the feedback loop of popular things getting more inbound links and so getting higher search ranking\'85and the impact stretches way beyond politics. \ldblquote You can push knowledge, beliefs, attitudes, and behavior among people who are vulnerable any way you want using search rankings,\rdblquote  Epstein says. \ldblquote Now that we\rquote ve discovered this big effect, how do you kill it?\rdblquote\par
\par
 \par
}
 